{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gQgJyhAPDn1X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bottleneck_residual_block(X, f, filters, stage, block, reduce=False, s=2):\n",
        "    \"\"\"    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, height, width, channels)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    reduce -- boolean, True = identifies the reduction layer at the beginning of each learning stage\n",
        "    s -- integer, strides\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (H, W, C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    if reduce:\n",
        "        # if we are to reduce the spatial size, apply a 1x1 CONV layer to the shortcut path\n",
        "        # to do that, we need both CONV layers to have similar strides \n",
        "        X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "        X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "        X = Activation('relu')(X)\n",
        "        \n",
        "        X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
        "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "        X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "    else: \n",
        "        # First component of main path\n",
        "        X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "        X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "        X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "metadata": {
        "id": "nwLsx2bMLdvI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(input_shape, classes):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    input_shape -- tuple shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X_input)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = bottleneck_residual_block(X, 3, [64, 64, 256], stage=2, block='a', reduce=True, s=1)\n",
        "    X = bottleneck_residual_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = bottleneck_residual_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 \n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='a', reduce=True, s=2)\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='a', reduce=True, s=2)\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = bottleneck_residual_block(X, 3, [512, 512, 2048], stage=5, block='a', reduce=True, s=2)\n",
        "    X = bottleneck_residual_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = bottleneck_residual_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL \n",
        "    X = AveragePooling2D((1,1), name=\"avg_pool\")(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    # Create the model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "KwAWsRZNNVbs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(input_shape = (32,32, 3), classes = 10)"
      ],
      "metadata": {
        "id": "8ywFpGcdOx2h"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = tf.constant(list(range(100*32*32*3)), dtype=tf.float32, shape=(100, 32, 32, 3))\n",
        "sample_label = tf.constant(list(range(100)), dtype=tf.int64)"
      ],
      "metadata": {
        "id": "tU03FvPeO2Zn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics = ['accuracy'])\n",
        "model.fit(sample, sample_label, epochs=1, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaxbpjA8PlOZ",
        "outputId": "05bcbffb-a2c8-493c-8730-b16d2258bb0c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 24s 376ms/step - loss: nan - accuracy: 0.0100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe10029190>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "91780860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c51da6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_module_fig5(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(Inception_module_fig5, self).__init__()\n",
    "        self.factorization_5x5_reduce = ConvBN(filters[0], 1, 1, 'same')\n",
    "        self.factorization_5x5_1 = ConvBN(filters[1], 3, 1, 'same')\n",
    "        self.factorization_5x5_2 = ConvBN(filters[2], 3, 1, 'same')\n",
    "        \n",
    "        self.factorization_3x3_reduce = ConvBN(filters[3], 1, 1, 'same')\n",
    "        self.factorization_3x3_1 = ConvBN(filters[4], 3, 1, 'same')\n",
    "        \n",
    "        self.factorization_pool_reduce = ConvBN(filters[5], 1, 1, 'same')\n",
    "        self.factorization_pool = layers.AveragePooling2D((3, 3), strides=1, padding='same')\n",
    "        \n",
    "        self.factorization_1x1 = ConvBN(filters[6], 1, 1, 'same')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        out1 = self.factorization_5x5_reduce(inputs)\n",
    "        out1 = self.factorization_5x5_1(out1)\n",
    "        out1 = self.factorization_5x5_2(out1)\n",
    "        \n",
    "        out2 = self.factorization_3x3_reduce(inputs)\n",
    "        out2 = self.factorization_3x3_1(out2)\n",
    "        \n",
    "        out3 = self.factorization_pool(inputs)\n",
    "        out3 = self.factorization_pool_reduce(out3)\n",
    "        \n",
    "        out4 = self.factorization_1x1(inputs)\n",
    "        \n",
    "        output = layers.concatenate([out1, out2, out3, out4], axis=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "db46a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_module_fig6(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(Inception_module_fig6, self).__init__()\n",
    "        self.factorization_7x7_reduce = ConvBN(filters, 1, 1, 'same')\n",
    "        self.factorization_7x7_1 = ConvBN(filters, (1, 7), 1, 'same')\n",
    "        self.factorization_7x7_2 = ConvBN(192, (7, 1), 1, 'same')\n",
    "        \n",
    "        self.factorization_7x7dbl_reduce = ConvBN(filters, 1, 1, 'same')\n",
    "        self.factorization_7x7dbl_1 = ConvBN(filters, (1, 7), 1, 'same')\n",
    "        self.factorization_7x7dbl_2 = ConvBN(filters, (7, 1), 1, 'same')\n",
    "        self.factorization_7x7dbl_3 = ConvBN(filters, (1, 7), 1, 'same')\n",
    "        self.factorization_7x7dbl_4 = ConvBN(192, (7, 1), 1, 'same')\n",
    "        \n",
    "        self.factorization_pool_reduce = ConvBN(192, 1, 1, 'same')\n",
    "        self.factorization_pool = layers.AveragePooling2D((3, 3), strides=1, padding='same')\n",
    "        \n",
    "        self.factorization_1x1 = ConvBN(192, 1, 1, 'same')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        out1 = self.factorization_7x7_reduce(inputs)\n",
    "        out1 = self.factorization_7x7_1(out1)\n",
    "        out1 = self.factorization_7x7_2(out1)\n",
    "        \n",
    "        out2 = self.factorization_7x7dbl_reduce(inputs)\n",
    "        out2 = self.factorization_7x7dbl_1(out2)\n",
    "        out2 = self.factorization_7x7dbl_2(out2)\n",
    "        out2 = self.factorization_7x7dbl_3(out2)\n",
    "        out2 = self.factorization_7x7dbl_4(out2)\n",
    "        \n",
    "        out3 = self.factorization_pool(inputs)\n",
    "        out3 = self.factorization_pool_reduce(out3)\n",
    "        \n",
    "        out4 = self.factorization_1x1(inputs)\n",
    "        \n",
    "        output = layers.concatenate([out1, out2, out3, out4], axis=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f6453b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_module_fig7(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Inception_module_fig7, self).__init__()\n",
    "        self.factorization_3x3_reduce = ConvBN(384, 1, 1, 'same')\n",
    "        self.factorization_3x1 = ConvBN(384, (1, 3), 1, 'same')\n",
    "        self.factorization_1x3 = ConvBN(384, (3, 1), 1, 'same')\n",
    "        \n",
    "        self.factorization_3x3dbl_reduce = ConvBN(448, 1, 1, 'same')\n",
    "        self.factorization_3x3dbl = ConvBN(384, 3, 1, 'same')\n",
    "        self.factorization_1x3dbl = ConvBN(384, (1, 3), 1, 'same')\n",
    "        self.factorization_3x1dbl = ConvBN(384, (3, 1), 1, 'same')\n",
    "        \n",
    "        self.factorization_pool_reduce = ConvBN(192, 1, 1, 'same')\n",
    "        self.factorization_pool = layers.AveragePooling2D((3, 3), strides=1, padding='same')\n",
    "        \n",
    "        self.factorization_1x1 = ConvBN(320, 1, 1, 'same')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        out1 = self.factorization_3x3_reduce(inputs)\n",
    "        out1_1 = self.factorization_3x1(out1)\n",
    "        out1_2 = self.factorization_1x3(out1)\n",
    "        out1 = layers.concatenate([out1_1, out1_2], axis=-1)\n",
    "        \n",
    "        \n",
    "        out2 = self.factorization_3x3dbl_reduce(inputs)\n",
    "        out2 = self.factorization_3x3dbl(out2)\n",
    "        out2_1 = self.factorization_1x3dbl(out2)\n",
    "        out2_2 = self.factorization_3x1dbl(out2)\n",
    "        out2 = layers.concatenate([out2_1, out2_2], axis=-1)\n",
    "        \n",
    "        out3 = self.factorization_pool(inputs)\n",
    "        out3 = self.factorization_pool_reduce(out3)\n",
    "        \n",
    "        out4 = self.factorization_1x1(inputs)\n",
    "        \n",
    "        output = layers.concatenate([out1, out2, out3, out4], axis=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7a2045a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Representations_17x17(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Representations_17x17, self).__init__()\n",
    "        self.factorization_5x5_reduce = ConvBN(64, 1, 1, 'same')\n",
    "        self.factorization_5x5_1 = ConvBN(96, 3, 1, 'same')\n",
    "        self.factorization_5x5_2 = ConvBN(96, 3, 2, 'valid')\n",
    "        \n",
    "        self.factorization_3x3_reduce = ConvBN(64, 1, 1, 'same')\n",
    "        self.factorization_3x3 = ConvBN(384, 3, 2, 'valid')\n",
    "        \n",
    "        self.pool = layers.MaxPooling2D((3, 3), (2, 2), padding='valid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        out1 = self.factorization_5x5_reduce(inputs)\n",
    "        out1 = self.factorization_5x5_1(out1)\n",
    "        out1 = self.factorization_5x5_2(out1)\n",
    "        \n",
    "        out2 = self.factorization_3x3_reduce(inputs)\n",
    "        out2 = self.factorization_3x3(out2)\n",
    "        \n",
    "        out3 = self.pool(inputs)\n",
    "        \n",
    "        output = layers.concatenate([out1, out2, out3], axis=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "34f5060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Representations_8x8(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Representations_8x8, self).__init__()\n",
    "        self.factorization_7x7x3_reduce = ConvBN(192, 1, 1, 'same')\n",
    "        self.factorization_7x7x3_1 = ConvBN(192, (1, 7), 1, 'same')\n",
    "        self.factorization_7x7x3_2 = ConvBN(192, (7, 1), 1, 'same')\n",
    "        self.factorization_7x7x3_3 = ConvBN(192, 3, 2, 'valid')\n",
    "        \n",
    "        self.factorization_3x3_reduce = ConvBN(192, 1, 1, 'same')\n",
    "        self.factorization_3x3 = ConvBN(320, 3, 2, 'valid')\n",
    "        \n",
    "        self.pool = layers.MaxPooling2D((3, 3), (2, 2), padding='valid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        out1 = self.factorization_7x7x3_reduce(inputs)\n",
    "        out1 = self.factorization_7x7x3_1(out1)\n",
    "        out1 = self.factorization_7x7x3_2(out1)\n",
    "        out1 = self.factorization_7x7x3_3(out1)\n",
    "        \n",
    "        out2 = self.factorization_3x3_reduce(inputs)\n",
    "        out2 = self.factorization_3x3(out2)\n",
    "        \n",
    "        out3 = self.pool(inputs)\n",
    "        \n",
    "        output = layers.concatenate([out1, out2, out3], axis=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ebaf46db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(layers.Layer):\n",
    "    def __init__(self, filters, ksize, s, pad, input_s=None):\n",
    "        super(ConvBN, self).__init__()\n",
    "        \n",
    "        if input_s is None:\n",
    "            self.conv = layers.Conv2D(filters, ksize, s, padding=pad)\n",
    "        else:\n",
    "            self.conv = layers.Conv2D(filters, ksize, s, padding=pad, input_shape=(input_s))\n",
    "        \n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.act = layers.Activation('relu')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.conv(inputs)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "73c7cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_v3(tf.keras.models.Model):\n",
    "    def __init__(self, num_class):\n",
    "        super(Inception_v3, self).__init__()\n",
    "        \n",
    "        reg = tf.keras.regularizers.L2(0.0001)\n",
    "        \n",
    "        self.conv1 = ConvBN(32, 3, 2, 'valid', (299, 299, 3))\n",
    "        self.conv2 = ConvBN(32, 3, 1, 'valid', None)\n",
    "        self.conv3 = ConvBN(64, 3, 1, 'same', None)\n",
    "        self.conv4 = ConvBN(80, 3, 1, 'valid', None)\n",
    "        self.conv5 = ConvBN(192, 3, 2, 'valid', None)\n",
    "        self.conv6 = ConvBN(288, 3, 1, 'same', None)\n",
    "        \n",
    "        self.pool1 = layers.MaxPooling2D((3, 3), 2)\n",
    "        \n",
    "        # 35 X 35 X 256 MIXED\n",
    "        self.inception1 = Inception_module_fig5([64, 96, 96, 48, 64, 32, 64])\n",
    "        \n",
    "        # 35 X 35 X 288 MIXED\n",
    "        self.inception2 = Inception_module_fig5([64, 96, 96, 48, 64, 64, 64])\n",
    "        self.inception3 = Inception_module_fig5([64, 96, 96, 48, 64, 64, 64])\n",
    "        \n",
    "        # Representation bottleneck 해결\n",
    "        self.representation_17 = Representations_17x17()\n",
    "        \n",
    "        # 17 X 17 X 768 MIXED\n",
    "        self.inception4 = Inception_module_fig6(128)\n",
    "        self.inception5 = Inception_module_fig6(160)\n",
    "        self.inception6 = Inception_module_fig6(160)\n",
    "        self.inception7 = Inception_module_fig6(192)\n",
    "        \n",
    "        # Representation bottleneck 해결\n",
    "        self.representation_8 = Representations_8x8()\n",
    "        \n",
    "        # 8 X 8 X 1280 MIXED\n",
    "        self.inception8 = Inception_module_fig7()\n",
    "        self.inception9 = Inception_module_fig7()\n",
    "        \n",
    "        # output\n",
    "        self.global_avg = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_class)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        \n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.inception3(x)\n",
    "        \n",
    "        x = self.representation_17(x)\n",
    "        \n",
    "        x = self.inception4(x)\n",
    "        x = self.inception5(x)\n",
    "        x = self.inception6(x)\n",
    "        x = self.inception7(x)\n",
    "        \n",
    "        x = self.representation_8(x)\n",
    "        \n",
    "        x = self.inception8(x)\n",
    "        x = self.inception9(x)\n",
    "        \n",
    "        x = self.global_avg(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c096a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Inception_v3(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a958586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tf.constant(list(range(299*299*3)), dtype=tf.float32, shape=(1, 299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "47d54c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1000])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "72d2a465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_bn_809 (ConvBN)         multiple                  1024      \n",
      "_________________________________________________________________\n",
      "conv_bn_810 (ConvBN)         multiple                  9376      \n",
      "_________________________________________________________________\n",
      "conv_bn_811 (ConvBN)         multiple                  18752     \n",
      "_________________________________________________________________\n",
      "conv_bn_812 (ConvBN)         multiple                  46480     \n",
      "_________________________________________________________________\n",
      "conv_bn_813 (ConvBN)         multiple                  139200    \n",
      "_________________________________________________________________\n",
      "conv_bn_814 (ConvBN)         multiple                  499104    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "inception_module_fig5_40 (In multiple                  228112    \n",
      "_________________________________________________________________\n",
      "inception_module_fig5_41 (In multiple                  229808    \n",
      "_________________________________________________________________\n",
      "inception_module_fig5_42 (In multiple                  237488    \n",
      "_________________________________________________________________\n",
      "representations_17x17_4 (Rep multiple                  399808    \n",
      "_________________________________________________________________\n",
      "inception_module_fig6_33 (In multiple                  1302016   \n",
      "_________________________________________________________________\n",
      "inception_module_fig6_34 (In multiple                  1696192   \n",
      "_________________________________________________________________\n",
      "inception_module_fig6_35 (In multiple                  1696192   \n",
      "_________________________________________________________________\n",
      "inception_module_fig6_36 (In multiple                  2147712   \n",
      "_________________________________________________________________\n",
      "representations_8x8_3 (Repre multiple                  1702144   \n",
      "_________________________________________________________________\n",
      "inception_module_fig7_2 (Inc multiple                  5054400   \n",
      "_________________________________________________________________\n",
      "inception_module_fig7_3 (Inc multiple                  6086592   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  2049000   \n",
      "=================================================================\n",
      "Total params: 23,543,400\n",
      "Trainable params: 23,508,264\n",
      "Non-trainable params: 35,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f7975185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2.\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
